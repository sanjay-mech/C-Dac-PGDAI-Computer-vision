{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rpIL_nQr-V-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the ResNet50 model\n",
        "model = ResNet50(weights='imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD0WEzzZsUBi",
        "outputId": "c1e25ef1-dca1-4f03-af2b-28baaab0f46f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102967424/102967424 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an image\n",
        "img_path = 'cat.webp'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "x = preprocess_input(x)"
      ],
      "metadata": {
        "id": "xHP7wCpms9PE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the class of the image\n",
        "preds = model.predict(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4kyVg3itb4d",
        "outputId": "e759d143-4f92-420d-bdb6-17553e2fd000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 218ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Predicted:', decode_predictions(preds, top=3)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ51QrwXtxkW",
        "outputId": "0984cc73-7fd5-4e7d-c17a-35570f33e9ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: [('n01877812', 'wallaby', 0.55635273), ('n02091244', 'Ibizan_hound', 0.13397415), ('n02326432', 'hare', 0.031962592)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(ResNet50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYmr_VmouI3H",
        "outputId": "2971c22c-cf47-47d6-98c9-aa3fbcaaca6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function ResNet50 in module keras.applications.resnet:\n",
            "\n",
            "ResNet50(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000, **kwargs)\n",
            "    Instantiates the ResNet50 architecture.\n",
            "    \n",
            "    Reference:\n",
            "    - [Deep Residual Learning for Image Recognition](\n",
            "        https://arxiv.org/abs/1512.03385) (CVPR 2015)\n",
            "    \n",
            "    For image classification use cases, see\n",
            "    [this page for detailed examples](\n",
            "      https://keras.io/api/applications/#usage-examples-for-image-classification-models).\n",
            "    \n",
            "    For transfer learning use cases, make sure to read the\n",
            "    [guide to transfer learning & fine-tuning](\n",
            "      https://keras.io/guides/transfer_learning/).\n",
            "    \n",
            "    Note: each Keras Application expects a specific kind of input preprocessing.\n",
            "    For ResNet, call `tf.keras.applications.resnet.preprocess_input` on your\n",
            "    inputs before passing them to the model.\n",
            "    `resnet.preprocess_input` will convert the input images from RGB to BGR,\n",
            "    then will zero-center each color channel with respect to the ImageNet dataset,\n",
            "    without scaling.\n",
            "    \n",
            "    Args:\n",
            "      include_top: whether to include the fully-connected\n",
            "        layer at the top of the network.\n",
            "      weights: one of `None` (random initialization),\n",
            "        'imagenet' (pre-training on ImageNet),\n",
            "        or the path to the weights file to be loaded.\n",
            "      input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
            "        to use as image input for the model.\n",
            "      input_shape: optional shape tuple, only to be specified\n",
            "        if `include_top` is False (otherwise the input shape\n",
            "        has to be `(224, 224, 3)` (with `'channels_last'` data format)\n",
            "        or `(3, 224, 224)` (with `'channels_first'` data format).\n",
            "        It should have exactly 3 inputs channels,\n",
            "        and width and height should be no smaller than 32.\n",
            "        E.g. `(200, 200, 3)` would be one valid value.\n",
            "      pooling: Optional pooling mode for feature extraction\n",
            "        when `include_top` is `False`.\n",
            "        - `None` means that the output of the model will be\n",
            "            the 4D tensor output of the\n",
            "            last convolutional block.\n",
            "        - `avg` means that global average pooling\n",
            "            will be applied to the output of the\n",
            "            last convolutional block, and thus\n",
            "            the output of the model will be a 2D tensor.\n",
            "        - `max` means that global max pooling will\n",
            "            be applied.\n",
            "      classes: optional number of classes to classify images\n",
            "        into, only to be specified if `include_top` is True, and\n",
            "        if no `weights` argument is specified.\n",
            "      classifier_activation: A `str` or callable. The activation function to use\n",
            "        on the \"top\" layer. Ignored unless `include_top=True`. Set\n",
            "        `classifier_activation=None` to return the logits of the \"top\" layer.\n",
            "        When loading pretrained weights, `classifier_activation` can only\n",
            "        be `None` or `\"softmax\"`.\n",
            "    \n",
            "    Returns:\n",
            "      A Keras model instance.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3l9Hl_Euu-w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}